{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production-Ready Agent Engineering: From MCP to RL\n",
    "\n",
    "### Lecture 2: Production-Grade Agents\n",
    "\n",
    "**Instructor: Will Brown**\n",
    "\n",
    "*Date: June 19, 2025*\n",
    "\n",
    "#### Agents as Software Programs\n",
    "- Typing\n",
    "- Testing Practices\n",
    "- Tools as Functions\n",
    "- Async Processing\n",
    "- Parallel Tool Execution\n",
    "\n",
    "#### System Architecture\n",
    "- Logging + Observability\n",
    "- Databases\n",
    "- Is RAG dead?\n",
    "- Client-Server (FastAPI, MCP, A2A)\n",
    "\n",
    "#### Security + Reliability\n",
    "- Environment Variables\n",
    "- Tools as Action Whitelists\n",
    "- Error handling + Retries\n",
    "- Code sandboxes\n",
    "    - Docker\n",
    "    - E2B\n",
    "    - Morph, Modal, Lambda\n",
    "- Auth + Permissioning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents as Software Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typing\n",
    "\n",
    "- Hints not mandatory in Python, but **strongly recommended**\n",
    "- \"Any\" as an escape hatch if needed, but \"Union\" preferable\n",
    "- Ensures reliable composability\n",
    "- Enable Pylance (Pyright) in IDE\n",
    "- Linting for code quality (Pylance, Ruff)\n",
    "    - Great for LLM-assisted development, many IDEs will show linter errors to LLMs, catches many bugs early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 1.6500000000000001, 3.3000000000000003]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"sloppy\" example\n",
    "\n",
    "def cumulative_returns(daily_returns):\n",
    "    \"\"\"\n",
    "    Return the running product of daily returns.\n",
    "    e.g. [1.1, 1.03, 1.04]  ->  [1.1, 1.133, 1.1783]\n",
    "    \"\"\"\n",
    "    acc = 1\n",
    "    totals = []\n",
    "    for ret in daily_returns:\n",
    "        acc *= ret\n",
    "        totals.append(acc)\n",
    "    return totals\n",
    "\n",
    "rets = [1.1, 1.5, 2]\n",
    "cumulative_returns(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth multiplier: 3\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "prompt = \"\"\"\n",
    "Value yesterday: 100\n",
    "\n",
    "Value today: 300\n",
    "\n",
    "Return the growth multiplier (number only).\n",
    "\"\"\"\n",
    "\n",
    "oai = OpenAI()\n",
    "\n",
    "response = oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "\n",
    "mult = response.choices[0].message.content\n",
    "print(f\"Growth multiplier: {mult}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 6, '333333']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets = [1, 3, 2]\n",
    "rets.append(mult) # type: ignore\n",
    "cumulative_returns(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333333'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 1.1330000000000002, 1.1783200000000003]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix: enforce type hints\n",
    "\n",
    "def cumulative_returns(daily_returns: list[float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Return the running product of daily returns.\n",
    "    e.g. [1.1, 1.03, 1.04]  ->  [1.1, 1.133, 1.1783]\n",
    "    \"\"\"\n",
    "    acc = 1\n",
    "    totals = []\n",
    "    for ret in daily_returns:\n",
    "        acc *= ret\n",
    "        totals.append(acc)\n",
    "    return totals\n",
    "\n",
    "rets = [1.1, 1.03, 1.04]\n",
    "cumulative_returns(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests...\n",
      "\n",
      "‚úÖ test_cumulative_returns_basic: PASSED\n",
      "‚úÖ test_cumulative_returns_single: PASSED\n",
      "‚úÖ test_cumulative_returns_empty: PASSED\n",
      "‚úÖ test_cumulative_returns_identity: PASSED\n",
      "‚úÖ test_cumulative_returns_negative: PASSED\n",
      "‚úÖ test_cumulative_returns_mixed: PASSED\n",
      "‚úÖ test_cumulative_returns_type_error: PASSED\n",
      "‚úÖ test_cumulative_returns_type_error_mixed: PASSED\n",
      "\n",
      "==================================================\n",
      "Results: 8 passed, 0 failed\n",
      "üéâ All tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytest cases for cumulative_returns\n",
    "\n",
    "import pytest\n",
    "\n",
    "def test_cumulative_returns_basic():\n",
    "    \"\"\"Test basic cumulative returns calculation\"\"\"\n",
    "    result = cumulative_returns([1.1, 1.03, 1.04])\n",
    "    expected = [1.1, 1.133, 1.17832]\n",
    "    for actual, expected_val in zip(result, expected):\n",
    "        assert actual == pytest.approx(expected_val, rel=1e-10)\n",
    "\n",
    "def test_cumulative_returns_single():\n",
    "    \"\"\"Test with single return value\"\"\"\n",
    "    assert cumulative_returns([1.5]) == [1.5]\n",
    "\n",
    "def test_cumulative_returns_empty():\n",
    "    \"\"\"Test with empty list\"\"\"\n",
    "    assert cumulative_returns([]) == []\n",
    "\n",
    "def test_cumulative_returns_identity():\n",
    "    \"\"\"Test with identity returns (1.0)\"\"\"\n",
    "    assert cumulative_returns([1.0, 1.0, 1.0]) == [1.0, 1.0, 1.0]\n",
    "\n",
    "def test_cumulative_returns_negative():\n",
    "    \"\"\"Test with negative returns\"\"\"\n",
    "    result = cumulative_returns([0.9, 0.8])\n",
    "    expected = [0.9, 0.72]\n",
    "    for actual, expected_val in zip(result, expected):\n",
    "        assert actual == pytest.approx(expected_val, rel=1e-10)\n",
    "\n",
    "def test_cumulative_returns_mixed():\n",
    "    \"\"\"Test with mixed positive and negative returns\"\"\"\n",
    "    result = cumulative_returns([1.1, 0.9, 1.2])\n",
    "    expected = [1.1, 0.99, 1.188]\n",
    "    for actual, expected_val in zip(result, expected):\n",
    "        assert actual == pytest.approx(expected_val, rel=1e-10)\n",
    "\n",
    "def test_cumulative_returns_type_error():\n",
    "    \"\"\"Test with string input\"\"\"\n",
    "    with pytest.raises(TypeError):\n",
    "        cumulative_returns([\"1.1\", \"1.03\", \"1.04\"]) # type: ignore\n",
    "\n",
    "def test_cumulative_returns_type_error_mixed():\n",
    "    \"\"\"Test with type error\"\"\"\n",
    "    with pytest.raises(TypeError):\n",
    "        cumulative_returns([1.1, \"1.03\", 1.04]) # type: ignore\n",
    "\n",
    "# Notebook-friendly test runner\n",
    "def run_tests():\n",
    "    \"\"\"Run all test functions and report results\"\"\"\n",
    "    test_functions = [\n",
    "        test_cumulative_returns_basic,\n",
    "        test_cumulative_returns_single,\n",
    "        test_cumulative_returns_empty,\n",
    "        test_cumulative_returns_identity,\n",
    "        test_cumulative_returns_negative,\n",
    "        test_cumulative_returns_mixed,\n",
    "        test_cumulative_returns_type_error,\n",
    "        test_cumulative_returns_type_error_mixed,\n",
    "    ]\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    print(\"Running tests...\\n\")\n",
    "\n",
    "    for test_func in test_functions:\n",
    "        try:\n",
    "            test_func()\n",
    "            print(f\"‚úÖ {test_func.__name__}: PASSED\")\n",
    "            passed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {test_func.__name__}: FAILED - {str(e)}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Results: {passed} passed, {failed} failed\")\n",
    "\n",
    "    if failed == 0:\n",
    "        print(\"üéâ All tests passed!\")\n",
    "\n",
    "    return failed == 0\n",
    "\n",
    "# Run the tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth multiplier: 3.0\n"
     ]
    }
   ],
   "source": [
    "# structured output\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "\"\"\"\n",
    "alternatives:\n",
    "- outlines\n",
    "- openai.beta.chat.completions.parse\n",
    "- openai.responses.create\n",
    "- JSON mode\n",
    "\"\"\"\n",
    "\n",
    "class GrowthMultiplier(BaseModel):\n",
    "    growth_multiplier: float\n",
    "\n",
    "prompt = \"\"\"\n",
    "Value yesterday: 100\n",
    "\n",
    "Value today: 300\n",
    "\n",
    "Return the growth multiplier (number only).\n",
    "\"\"\"\n",
    "\n",
    "oai = OpenAI()\n",
    "instructor_oai = instructor.from_openai(oai)\n",
    "\n",
    "response = instructor_oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_model=GrowthMultiplier, # type: ignore\n",
    ")\n",
    "\n",
    "print(f\"Growth multiplier: {response.growth_multiplier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.growth_multiplier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools as Functions\n",
    "\n",
    "Test your tools! Your agent's reliability is only as good as its tools' reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Error: Invalid characters in expression\n",
      "0.0007704043753812719\n",
      "---\n",
      "The value of \\(\\frac{62565374 + 265345356}{425634563456}\\) is approximately 0.0007704.\n",
      "---\n",
      "Let's perform the calculations step-by-step:\n",
      "\n",
      "First, add the numerators:\n",
      "62565374 + 265345356 = 327910730\n",
      "\n",
      "Next, divide this sum by the denominator:\n",
      "327910730 / 425634563456\n",
      "\n",
      "Now, compute the division:\n",
      "‚âà 7.693 x 10‚Åª‚Å¥\n",
      "\n",
      "So, the answer is approximately **0.0007693**.\n"
     ]
    }
   ],
   "source": [
    "# openai agents sdk\n",
    "# uv add openai-agents\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluates a single line of Python math expression. No imports or variables allowed.\n",
    "\n",
    "    Args:\n",
    "        expression (str): A mathematical expression using only numbers and basic operators (+,-,*,/,**,())\n",
    "\n",
    "    Returns:\n",
    "        The result of the calculation or an error message\n",
    "\n",
    "    Examples:\n",
    "        \"2 + 2\" -> \"4\"\n",
    "        \"3 * (17 + 4)\" -> \"63\"\n",
    "        \"100 / 5\" -> \"20.0\"\n",
    "    \"\"\"\n",
    "    allowed = set(\"0123456789+-*/.() \")\n",
    "    if not all(c in allowed for c in expression):\n",
    "        return \"Error: Invalid characters in expression\"\n",
    "\n",
    "    try:\n",
    "        # eval is a dangerous function, use with caution\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(calculator(\"2 + 2\"))\n",
    "print(calculator(\"3 x (17 + 4)\"))\n",
    "print(calculator(\"(62565374 + 265345356) / 425634563456\"))\n",
    "\n",
    "prompt = \"\"\"\n",
    "What is (62565374 + 265345356) / 425634563456?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@function_tool\n",
    "async def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"Evaluates a single line of Python math expression. No imports or variables allowed.\n",
    "\n",
    "    Args:\n",
    "        expression (str): A mathematical expression using only numbers and basic operators (+,-,*,/,**,())\n",
    "\n",
    "    Returns:\n",
    "        The result of the calculation or an error message\n",
    "\n",
    "    Examples:\n",
    "        \"2 + 2\" -> \"4\"\n",
    "        \"3 * (17 + 4)\" -> \"63\"\n",
    "        \"100 / 5\" -> \"20.0\"\n",
    "    \"\"\"\n",
    "    return calculator(expression)\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    name=\"calculator_agent\",\n",
    "    tools=[calculator_tool],\n",
    ")\n",
    "print(\"---\")\n",
    "\n",
    "result = Runner.run_sync(agent, prompt)\n",
    "print(result.final_output)\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    name=\"calculator_agent\",\n",
    "    tools=[],\n",
    ")\n",
    "print(\"---\")\n",
    "result = Runner.run_sync(agent, prompt)\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who are the 10 most famous basketball players?\n",
      "Who are the 10 most famous tennis players?\n",
      "Who are the 10 most famous soccer players?\n",
      "Who are the 10 most famous baseball players?\n",
      "Who are the 10 most famous hockey players?\n",
      "Who are the 10 most famous golf players?\n",
      "Who are the 10 most famous tennis players?\n",
      "Who are the 10 most famous soccer players?\n",
      "Who are the 10 most famous baseball players?\n",
      "Who are the 10 most famous hockey players?\n",
      "Who are the 10 most famous golf players?\n"
     ]
    }
   ],
   "source": [
    "# naive synchronous calls\n",
    "\n",
    "prompts = []\n",
    "\n",
    "keywords = [\"basketball\", \"tennis\", \"soccer\", \"baseball\", \"hockey\", \"golf\", \"tennis\", \"soccer\", \"baseball\", \"hockey\", \"golf\"]\n",
    "\n",
    "for keyword in keywords:\n",
    "    prompts.append(f\"Who are the 10 most famous {keyword} players?\")\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Player(name='Michael Jordan'), Player(name='LeBron James'), Player(name='Kobe Bryant'), Player(name=\"Shaquille O'Neal\"), Player(name='Tim Duncan'), Player(name='Larry Bird'), Player(name='Magic Johnson'), Player(name='Kareem Abdul-Jabbar'), Player(name='Bill Russell'), Player(name='Stephen Curry')]\n",
      "[Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Novak Djokovic'), Player(name='Serena Williams'), Player(name='Steffi Graf'), Player(name='Martina Navratilova'), Player(name='Pete Sampras'), Player(name='Bjorn Borg'), Player(name='Andre Agassi'), Player(name='Venus Williams')]\n",
      "[Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Neymar Jr'), Player(name='Kylian Mbappe'), Player(name='Mohamed Salah'), Player(name='Kevin De Bruyne'), Player(name='Robert Lewandowski'), Player(name='Harry Kane'), Player(name='Erling Haaland'), Player(name='Sadio Mane')]\n",
      "[Player(name='Babe Ruth'), Player(name='Jackie Robinson'), Player(name='Hank Aaron'), Player(name='Willie Mays'), Player(name='Ted Williams'), Player(name='Lou Gehrig'), Player(name='Joe DiMaggio'), Player(name='Mickey Mantle'), Player(name='Ty Cobb'), Player(name='Derek Jeter')]\n",
      "[Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Maurice Richard'), Player(name='Jean Beliveau'), Player(name='Sidney Crosby'), Player(name='Alexander Ovechkin'), Player(name='Patrick Roy'), Player(name='Mark Messier')]\n",
      "[Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Ben Hogan'), Player(name='Gary Player'), Player(name='Sam Snead'), Player(name='Bobby Jones'), Player(name='Phil Mickelson'), Player(name='Rory McIlroy'), Player(name='Walter Hagen')]\n",
      "[Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Novak Djokovic'), Player(name='Serena Williams'), Player(name='Venus Williams'), Player(name='Pete Sampras'), Player(name='Andre Agassi'), Player(name='Steffi Graf'), Player(name='Martina Navratilova'), Player(name='Bj√∂rn Borg')]\n",
      "[Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Pel√©'), Player(name='Diego Maradona'), Player(name='Neymar'), Player(name='Kylian Mbapp√©'), Player(name='Zinedine Zidane'), Player(name='David Beckham'), Player(name='Johan Cruyff'), Player(name='Ronaldinho')]\n",
      "[Player(name='Babe Ruth'), Player(name='Willie Mays'), Player(name='Hank Aaron'), Player(name='Ted Williams'), Player(name='Jackie Robinson'), Player(name='Lou Gehrig'), Player(name='Mickey Mantle'), Player(name='Joe DiMaggio'), Player(name='Stan Musial'), Player(name='Cy Young')]\n",
      "[Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Jaromir Jagr'), Player(name='Sidney Crosby'), Player(name='Alexander Ovechkin'), Player(name='Patrick Roy'), Player(name='Mark Messier'), Player(name='Jean Beliveau')]\n",
      "[Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Ben Hogan'), Player(name='Gary Player'), Player(name='Bobby Jones'), Player(name='Sam Snead'), Player(name='Phil Mickelson'), Player(name='Tom Watson'), Player(name='Rory McIlroy')]\n"
     ]
    }
   ],
   "source": [
    "class Player(BaseModel):\n",
    "    name: str\n",
    "\n",
    "class Players(BaseModel):\n",
    "    players: list[Player]\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    response = instructor_oai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_model=Players,\n",
    "    )\n",
    "    print(response.players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Player(name='Michael Jordan'), Player(name='LeBron James'), Player(name='Kobe Bryant'), Player(name=\"Shaquille O'Neal\"), Player(name='Larry Bird'), Player(name='Magic Johnson'), Player(name='Tim Duncan'), Player(name='Kareem Abdul-Jabbar'), Player(name='Bill Russell'), Player(name='Kevin Durant')], [Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Serena Williams'), Player(name='Novak Djokovic'), Player(name='Pete Sampras'), Player(name='Steffi Graf'), Player(name='Venus Williams'), Player(name='Andy Murray'), Player(name='Maria Sharapova'), Player(name='Bjorn Borg')], [Player(name='Pel√©'), Player(name='Diego Maradona'), Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Johan Cruyff'), Player(name='Zinedine Zidane'), Player(name='David Beckham'), Player(name='Ronaldinho'), Player(name='Michel Platini'), Player(name='Franz Beckenbauer')], [Player(name='Babe Ruth'), Player(name='Willie Mays'), Player(name='Hank Aaron'), Player(name='Ted Williams'), Player(name='Ty Cobb'), Player(name='Lou Gehrig'), Player(name='Jackie Robinson'), Player(name='Mickey Mantle'), Player(name='Joe DiMaggio'), Player(name='Albert Pujols')], [Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Sidney Crosby'), Player(name='Alexander Ovechkin'), Player(name='Jaromir Jagr'), Player(name='Patrick Roy'), Player(name='Mark Messier'), Player(name='Steve Yzerman')], [Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Ben Hogan'), Player(name='Bobby Jones'), Player(name='Gary Player'), Player(name='Sam Snead'), Player(name='Phil Mickelson'), Player(name='Seve Ballesteros'), Player(name='Rory McIlroy')], [Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Serena Williams'), Player(name='Novak Djokovic'), Player(name='Pete Sampras'), Player(name='Martina Navratilova'), Player(name='Bjorn Borg'), Player(name='Steffi Graf'), Player(name='Andre Agassi'), Player(name='Venus Williams')], [Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Neymar Jr'), Player(name='Kylian Mbappe'), Player(name='Mohamed Salah'), Player(name='Kevin De Bruyne'), Player(name='Robert Lewandowski'), Player(name='Karim Benzema'), Player(name='Harry Kane'), Player(name='Erling Haaland')], [Player(name='Babe Ruth'), Player(name='Willie Mays'), Player(name='Hank Aaron'), Player(name='Ted Williams'), Player(name='Jackie Robinson'), Player(name='Lou Gehrig'), Player(name='Mickey Mantle'), Player(name='Ty Cobb'), Player(name='Joe DiMaggio'), Player(name='Stan Musial')], [Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Sidney Crosby'), Player(name='Alexander Ovechkin'), Player(name='Patrick Roy'), Player(name='Martin Brodeur'), Player(name='Jaromir Jagr'), Player(name='Steve Yzerman')], [Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Rory McIlroy'), Player(name='Phil Mickelson'), Player(name='Gary Player'), Player(name='Ben Hogan'), Player(name='Bobby Jones'), Player(name='Sam Snead'), Player(name='Tom Watson')]]\n"
     ]
    }
   ],
   "source": [
    "# async version of the above\n",
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # needed for jupyter notebooks\n",
    "\n",
    "oai = AsyncOpenAI()\n",
    "instructor_oai = instructor.from_openai(oai)\n",
    "\n",
    "async def get_players(keyword: str) -> list[Player]:\n",
    "    response = await instructor_oai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Who are the 10 most famous {keyword} players?\"}],\n",
    "        response_model=Players,\n",
    "    )\n",
    "    return response.players\n",
    "\n",
    "# run all in parallel\n",
    "async def main():\n",
    "    tasks = [get_players(keyword) for keyword in keywords]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = asyncio.run(main())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Player(name='Michael Jordan'), Player(name='LeBron James'), Player(name='Kobe Bryant'), Player(name=\"Shaquille O'Neal\"), Player(name='Tim Duncan'), Player(name='Larry Bird'), Player(name='Magic Johnson'), Player(name='Kareem Abdul-Jabbar'), Player(name='Wilt Chamberlain'), Player(name='Bill Russell')], [Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Novak Djokovic'), Player(name='Serena Williams'), Player(name='Venus Williams'), Player(name='Pete Sampras'), Player(name='Andre Agassi'), Player(name='Martina Navratilova'), Player(name='Steffi Graf'), Player(name='Bjorn Borg')], [Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Neymar Jr.'), Player(name='Kylian Mbappe'), Player(name='Mohamed Salah'), Player(name='Kevin De Bruyne'), Player(name='Robert Lewandowski'), Player(name='Luka Modric'), Player(name='Virgil van Dijk'), Player(name='Karim Benzema')], [Player(name='Babe Ruth'), Player(name='Willie Mays'), Player(name='Hank Aaron'), Player(name='Ted Williams'), Player(name='Jackie Robinson'), Player(name='Ty Cobb'), Player(name='Mickey Mantle'), Player(name='Lou Gehrig'), Player(name='Joe DiMaggio'), Player(name='Derek Jeter')], [Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Alexander Ovechkin'), Player(name='Sidney Crosby'), Player(name='Patrick Roy'), Player(name='Martin Brodeur'), Player(name='Jaromir Jagr'), Player(name='Mark Messier')], [Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Phil Mickelson'), Player(name='Ben Hogan'), Player(name='Gary Player'), Player(name='Bobby Jones'), Player(name='Sam Snead'), Player(name='Tom Watson'), Player(name='Seve Ballesteros')], [Player(name='Roger Federer'), Player(name='Rafael Nadal'), Player(name='Novak Djokovic'), Player(name='Serena Williams'), Player(name='Steffi Graf'), Player(name='Pete Sampras'), Player(name='Andre Agassi'), Player(name='Martina Navratilova'), Player(name='Bjorn Borg'), Player(name='Venus Williams')], [Player(name='Lionel Messi'), Player(name='Cristiano Ronaldo'), Player(name='Neymar Jr.'), Player(name='Kylian Mbappe'), Player(name='Mohamed Salah'), Player(name='Kevin De Bruyne'), Player(name='Robert Lewandowski'), Player(name='Sadio Mane'), Player(name='Eden Hazard'), Player(name='Harry Kane')], [Player(name='Babe Ruth'), Player(name='Willie Mays'), Player(name='Hank Aaron'), Player(name='Ted Williams'), Player(name='Lou Gehrig'), Player(name='Jackie Robinson'), Player(name='Mickey Mantle'), Player(name='Joe DiMaggio'), Player(name='Cy Young'), Player(name='Ty Cobb')], [Player(name='Wayne Gretzky'), Player(name='Mario Lemieux'), Player(name='Bobby Orr'), Player(name='Gordie Howe'), Player(name='Patrick Roy'), Player(name='Jaromir Jagr'), Player(name='Sidney Crosby'), Player(name='Alexander Ovechkin'), Player(name='Nicklas Lidstrom'), Player(name='Martin Brodeur')], [Player(name='Tiger Woods'), Player(name='Jack Nicklaus'), Player(name='Arnold Palmer'), Player(name='Phil Mickelson'), Player(name='Rory McIlroy'), Player(name='Bobby Jones'), Player(name='Ben Hogan'), Player(name='Gary Player'), Player(name='Seve Ballesteros'), Player(name='Sam Snead')]]\n"
     ]
    }
   ],
   "source": [
    "# semaphore version of the above\n",
    "\n",
    "async def get_players_sem(keyword: str, semaphore: asyncio.Semaphore) -> list[Player]:\n",
    "    async with semaphore:\n",
    "        response = await instructor_oai.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Who are the 10 most famous {keyword} players?\"}],\n",
    "            response_model=Players,\n",
    "        )\n",
    "        return response.players\n",
    "\n",
    "# run all in parallel\n",
    "async def main():\n",
    "    semaphore = asyncio.Semaphore(5) # limit concurrent requests\n",
    "    tasks = [get_players_sem(keyword, semaphore) for keyword in keywords]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = asyncio.run(main())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCall(name='calculator', args={'expression': '(62565374 + 265345356) / 425634563456'}), ToolCall(name='calculator', args={'expression': '((426336 * 23423563563456) + 55363563) / 3456345636'}), ToolCall(name='calculator', args={'expression': '(62565374 + 265345356) / 425634563456'}), ToolCall(name='calculator', args={'expression': '((426336 * 23423563563456) + 55363563) / 3456345636'}), ToolCall(name='calculator', args={'expression': '(62565374 + 265345356) / 425634563456'}), ToolCall(name='calculator', args={'expression': '((426336 * 23423563563456) + 55363563) / 3456345636'})]\n"
     ]
    }
   ],
   "source": [
    "# same idea for tool calls\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    args: dict\n",
    "\n",
    "class ToolCalls(BaseModel):\n",
    "    thinking: str\n",
    "    tool_calls: list[ToolCall]\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "What is (62565374 + 265345356) / 425634563456?\n",
    "\n",
    "What is ((426336 * 23423563563456) + 55363563) / 3456345636?\n",
    "\n",
    "What is (62565374 + 265345356) / 425634563456?\n",
    "\n",
    "What is ((426336 * 23423563563456) + 55363563) / 3456345636?\n",
    "\n",
    "What is (62565374 + 265345356) / 425634563456?\n",
    "\n",
    "What is ((426336 * 23423563563456) + 55363563) / 3456345636?\n",
    "\n",
    "Use the calculator tool to calculate the answers to the questions.\n",
    "- name: calculator\n",
    "- args:\n",
    "    - expression: str\n",
    "\"\"\"\n",
    "\n",
    "oai = OpenAI()\n",
    "instructor_oai = instructor.from_openai(oai)\n",
    "\n",
    "response = instructor_oai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_model=ToolCalls,\n",
    ")\n",
    "\n",
    "print(response.tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculate the given expressions using the calculator tool with correct arguments.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.thinking\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "<thinking>\n",
    "Let's think step by step.\n",
    "...\n",
    "</thinking>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0007704043753812719', '2889267870.5020986', '0.0007704043753812719', '2889267870.5020986', '0.0007704043753812719', '2889267870.5020986']\n"
     ]
    }
   ],
   "source": [
    "# asynchronously execute tool calls\n",
    "\n",
    "async def execute_tool(func, args) -> str:\n",
    "    return func(**args)\n",
    "\n",
    "# run all in parallel\n",
    "async def main():\n",
    "    tasks = [execute_tool(calculator, tool_call.args)\n",
    "             for tool_call in response.tool_calls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = asyncio.run(main())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Fetch RAG vs Agentic RAG\n",
    "\n",
    "#### RAG = Retrieval-Augmented Generation\n",
    "\n",
    "- MCP-aided search agents = RAG\n",
    "- Deep Research = RAG\n",
    "\n",
    "#### Pre-Fetch RAG\n",
    "- search *before* LLM calls\n",
    "- example from previous lecture:\n",
    "    - \"helper agent\" = pre-fetch RAG\n",
    "    - common confusion: vector DBs != RAG\n",
    "- good if:\n",
    "    - docs aren't too long\n",
    "    - you want to cache docs for multiple Qs\n",
    "    - don't need \"multi-hop\" search, just \"easy lookup\"\n",
    "\n",
    "#### Agentic RAG\n",
    "- retrieved info isn't determined by \"always on\" program logic\n",
    "- good for:\n",
    "    - leveraging existing DB indexes/search tools\n",
    "    - retries / adaptive queries are \"native\"\n",
    "    - combining multiple data sources\n",
    "- Pro tips:\n",
    "    - Markdown docs are LLM-friendly, OCR and/or markdownify are great\n",
    "    - Leverage natural file system + link structures\n",
    "    - LLMs are great at clever plaintext search!\n",
    "- Generally recommended as default pattern "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Architecture\n",
    "\n",
    "### Logging + Monitoring\n",
    "\n",
    "Popular options\n",
    "- PydanticAI Logfire\n",
    "    - https://ai.pydantic.dev/\n",
    "- W&B Weave\n",
    "    - https://github.com/wandb/weave \n",
    "- MLFlow Tracing\n",
    "    - https://mlflow.org/docs/latest/genai/tracing\n",
    "- Arize Phoenix \n",
    "    - https://github.com/Arize-ai/phoenix \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:01:02.355 Hello, world!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \n",
      "\u001b]8;id=948297;https://logfire-us.pydantic.dev/williambrown97/starter-project\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/williambrown97/starter-project\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import logfire\n",
    "\n",
    "logfire.configure()\n",
    "logfire.info(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:50:43.860 calculator_agent run\n",
      "19:50:43.861   chat gpt-4.1-mini\n",
      "19:50:44.630   running 1 tool\n",
      "19:50:44.630     running tool: calculator_tool\n",
      "19:50:44.631   chat gpt-4.1-mini\n",
      "AgentRunResult(output=CalculatorResponse(float_result=4.0))\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "logfire.instrument_asyncpg()\n",
    "\n",
    "class CalculatorDependencies(BaseModel):\n",
    "    expression: str\n",
    "\n",
    "class CalculatorResponse(BaseModel):\n",
    "    float_result: float\n",
    "\n",
    "calculator_agent = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    deps_type=CalculatorDependencies,\n",
    "    output_type=CalculatorResponse,\n",
    "    system_prompt=\"\"\"\n",
    "    You are a helpful assistant that can calculate the result of a mathematical expression.\n",
    "    \"\"\",\n",
    "    instrument=True\n",
    ")\n",
    "\n",
    "@calculator_agent.tool\n",
    "async def calculator_tool(context: RunContext[CalculatorDependencies]) -> float:\n",
    "    return float(calculator(context.deps.expression))\n",
    "\n",
    "async def main():\n",
    "    deps = CalculatorDependencies(expression=\"2 + 2\")\n",
    "    response = await calculator_agent.run(\"What is the answer?\", deps=deps)\n",
    "    print(response)\n",
    "\n",
    "result = asyncio.run(main())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP + Client-Server Architectures\n",
    "\n",
    "#### API Servers\n",
    "\n",
    "- see `servers/fetch_wiki.py` + `tests/test_fetch_wiki_search.py`\n",
    "\n",
    "#### MCP as \"API Servers for LLMs\"\n",
    "- see https://github.com/modelcontextprotocol/servers/blob/main/src/fetch/src/mcp_server_fetch/server.py\n",
    "\n",
    "related projects of mine:\n",
    "- https://github.com/willccbb/claude-code-mcp\n",
    "- https://github.com/willccbb/claude-deep-research\n",
    "- https://github.com/willccbb/mcp-client-server\n",
    "\n",
    "MCP repositories\n",
    "- official page: https://github.com/modelcontextprotocol/servers \n",
    "- https://smithery.ai/ \n",
    "- https://mcp.so/\n",
    "\n",
    "Popular clients:\n",
    "- Cursor, Windsurf\n",
    "- Claude Code\n",
    "- ChatGPT\n",
    "\n",
    "```bash\n",
    "# installable js/ts servers\n",
    "claude mcp add filesystem -- npx -y @modelcontextprotocol/server-filesystem $CLAUDE_FILESYSTEM_PATH\n",
    "claude mcp add brave-search -e BRAVE_API_KEY=$BRAVE_API_KEY -- npx -y @modelcontextprotocol/server-brave-search\n",
    "claude mcp add e2b -e E2B_API_KEY=$E2B_API_KEY -- npx -y @e2b/mcp-server \n",
    "\n",
    "# installable python servers\n",
    "claude mcp add fetch uvx mcp-server-fetch\n",
    "\n",
    "claude\n",
    "```\n",
    "\n",
    "Transport protocols:\n",
    "- stdio: local-friendly\n",
    "- Streamable HTTP: primary remote server connection protocol (good support for streaming results, long-lived connections, availability, interrupts)\n",
    "- SSE: original remote protocol, but MCP is moving away from it\n",
    "- more info: [SSE vs Streamable HTTP](https://brightdata.com/blog/ai/sse-vs-streamable-http)\n",
    "\n",
    "\n",
    "A2A:\n",
    "- \"Multi-Agent Layer\", similar to MCP, but compatible with it\n",
    "- Less useful in the \"agents as tools\" paradigm\n",
    "- Worth being aware of, but perhaps a bit early to go all-in\n",
    "\n",
    "#### Databases\n",
    "\n",
    "- File systems (e.g. Docker)\n",
    "    - tools: grep, sed, ls, cd, pwd, etc.\n",
    "- SQL databases\n",
    "    - tools: SQL query access (or limited wrappers, e.g. for read-only, id lookup, no joins, etc.)\n",
    "    - SQLite, Postgres, \n",
    "- Vector databases\n",
    "    - tools: querying for embedding similarity, ids\n",
    "    - Chroma, Weaviate, Pinecone, Milvus, MongoDB Atlas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Article Endpoint (Markdown) ===\n",
      "Status: 200\n",
      "Content length: 167288 characters\n",
      "First 2000 characters:\n",
      "# Python (programming language)\n",
      "\n",
      "General-purpose programming language\n",
      "\n",
      "**Python** is a [high-level](/wiki/High-level_programming_language \"High-level programming language\"), [general-purpose programming language](/wiki/General-purpose_programming_language \"General-purpose programming language\"). Its design philosophy emphasizes [code readability](/wiki/Code_readability \"Code readability\") with the use of [significant indentation](/wiki/Significant_indentation \"Significant indentation\").\n",
      "\n",
      "Python is [dynamically type-checked](/wiki/Type_system#DYNAMIC \"Type system\") and [garbage-collected](/wiki/Garbage_collection_(computer_science) \"Garbage collection (computer science)\"). It supports multiple [programming paradigms](/wiki/Programming_paradigm \"Programming paradigm\"), including [structured](/wiki/Structured_programming \"Structured programming\") (particularly [procedural](/wiki/Procedural_programming \"Procedural programming\")), [object-oriented](/wiki/Object-oriented \"Object-oriented\") and [functional programming](/wiki/Functional_programming \"Functional programming\"). It is often described as a \"batteries included\" language due to its comprehensive [standard library](/wiki/Standard_library \"Standard library\").\n",
      "\n",
      "[Guido van Rossum](/wiki/Guido_van_Rossum \"Guido van Rossum\") began working on Python in the late 1980s as a successor to the [ABC](/wiki/ABC_(programming_language) \"ABC (programming language)\") programming language, and he first released it in 1991 as Python¬†0.9.0. Python¬†2.0 was released in 2000. Python¬†3.0, released in 2008, was a major revision not completely [backward-compatible](/wiki/Backward-compatible \"Backward-compatible\") with earlier versions. Python¬†2.7.18, released in 2020, was the last release of Python¬†2.\n",
      "\n",
      "Python consistently ranks as one of the most popular programming languages, and it has gained widespread use in the [machine learning](/wiki/Machine_learning \"Machine learning\") community.\n",
      "\n",
      "## History\n",
      "\n",
      "Main article: [History of Python](/wiki/History_of_Python \"History of Python\")\n",
      "[![](//upload.wikimedia.org/wikipedia/commons/thumb/2/21/Guido_van_Rossum_in_PyConUS24.jpg/250px-Guido_van_Rossum_in_PyConUS24.jpg)](/wiki/File:Guido_van_Rossum_in_PyConUS24.jpg)\n",
      "\n",
      "The designer of Python, [Guido van Rossum](/wiki/Guido_van_Rossum \"Guido van Rossum\"), at PyCon US 2024\n",
      "\n",
      "Python was conceived in the late 1980s by Guido van Rossum at [Centrum Wiskunde & Informatica](/wiki/Centrum_Wiskunde_%26_Informatica \"Centrum Wiskunde & Informatica\") (CWI) in the [Netherlands](/wiki/Netherlands \"Netherlands\"); it was conceived as a successor to the [ABC](/wiki/ABC_(programming_language) \"ABC (programming language)\") programming language, which was inspired by [SETL](/wiki/SETL \"SETL\"), capable of [exception handling](/wiki/Exception_handling \"Exception handling\") and interfacing with the [Amoeba](/wiki/Amoeba_(operating_system) \"Amoeba (operating system)\") operating system. Python implementation began in December,¬†1989. Van Rossum assumed sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from responsibilities as Python's \"[benevolent dictator for life](/wiki/Benevolent_dictator_for_life \"Benevolent dictator for life\")\" (BDFL); this title was bestowed on him by the Python community to reflect his long-term commitment as the project's chief decision-maker. (He has since come out of retirement and is self-titled \"BDFL-emeritus\".) In January,¬†2019, active Python core developers elected a five-member Steering Council to lead the project.\n",
      "\n",
      "The name *Python* is said to derive from the British comedy series [Monty Python's Flying Circus](/wiki/Monty_Python%27s_Flying_Circus \"Monty Python's Flying Circus\").\n",
      "\n",
      "Python 2.0 was released on 16 October 2000, with many major new features such as [list comprehensions](/wiki/List_comprehension \"List comprehension\"), [cycle-detecting](/wiki/Cycle_detection \"Cycle detection\") garbage collection, [reference counting](/wiki/Reference_counting \"Reference counting\"), and [Unicode](/wiki/Unicode \"Unicode\") support. Python 2.7's [end-of-life](/wiki/End-of-life_product \"End-of-life product\") was initially set for 2015, and then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python¬†3. It no longer receives security patches or updates. While Python 2.7 and older versions are officially unsupported, a different unofficial Python implementation, [PyPy](/wiki/PyPy \"PyPy\"), continues to support Python 2, i.e., \"2.7.18+\" (plus 3.10), with the plus signifying (at least some) \"[backported](/wiki/Backporting \"Backporting\") security updates\".\n",
      "\n",
      "Python¬†3.0 was released on 3 December 2008, with some new semantics and changed syntax. At least every Python release since (the now unsupported) 3.5 has added some syntax to the language; a few later releases have removed outdated modules and have changed semantics, at least in a minor way.\n",
      "\n",
      "As of 8¬†April¬†2025, Python 3.13.3 is ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "\n",
    "def test_article_endpoint():\n",
    "    \"\"\"Test getting an article as markdown.\"\"\"\n",
    "    print(\"=== Testing Article Endpoint (Markdown) ===\")\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/article\", params={\"title\": \"Python (programming language)\"})\n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        content = response.text\n",
    "        print(f\"Content length: {len(content)} characters\")\n",
    "        print(\"First 2000 characters:\")\n",
    "        print(content[:5000] + \"...\" if len(content) > 5000 else content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    print()\n",
    "\n",
    "test_article_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security\n",
    "\n",
    "### Tools as Action Whitelists\n",
    "\n",
    "Tempting:\n",
    "- Give your agent a terminal\n",
    "\n",
    "Challenges: \n",
    "- Workspace management (excess scripts)\n",
    "- Bad practices\n",
    "- Deleting important files\n",
    "\n",
    "Workaround:\n",
    "- \"Whitelist\" certain code paths\n",
    "- Explicit tools for common actions (e.g. fetching a website and converting to markdown)\n",
    "\n",
    "### Error Handling + Retries\n",
    "\n",
    "- Decide when to warn, retry, hard fail\n",
    "\n",
    "### Code Sandboxes\n",
    "- e2b ([MCP server](https://github.com/e2b-dev/mcp-server))\n",
    "- Morph, Modal, AWS Lambda, etc\n",
    "\n",
    "### Authorization + Permissioning\n",
    "- MCP is auth-optional by default\n",
    "- Typical auth best practices still apply\n",
    "- Default: agent is acting on behalf of a user, treated as user program requests\n",
    "https://modelcontextprotocol.io/specification/draft/basic/authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
